Demo run lexicraft.py with scrapping maximum 1 article(s)...
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
24/12/21 16:12:16 WARN Utils: Your hostname, Liang. resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)
24/12/21 16:12:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/21 16:12:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Performing Data Collection from time 2024-12-21 06:05:50.395568...
Links crawl to datetime  2024-12-21 16:12:19.006479
Links Crawling Starts...
Article teaser found on page 0.
Current no. of link: 20
Article teaser found on page 1.
Current no. of link: 36
Current is in demo stage, 1 number of article(s) will be scrapped
[Stage 0:>                                                        (0 + 12) / 12][Stage 1:>                                                          (0 + 3) / 3]/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
[Stage 1:===================>                                       (1 + 2) / 3][Stage 1:=======================================>                   (2 + 1) / 3]                                                                                Data sent to topic beritaH
Number of articles data sent 1
Performing Data Transformation...
Collecting Data From Kafka...
Is this your first time running the system?
If not please contact support as there is problem in accessing the DE-prj/RawData file in your hadoop file system.
[Stage 2:====================================================>    (11 + 1) / 12]                                                                                Breaking raw data into list of sentences...
Breaking sentences into words...
[Stage 6:===========================================>              (9 + 3) / 12]                                                                                [Stage 7:===========================================>              (9 + 3) / 12]                                                                                /bin/sh: 1: hdfs: not found
['/home/hduser/hadoop3/bin/hadoop', 'jar', '/home/hduser/hadoop3/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar', '-input', 'hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00000-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00001-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00002-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00003-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00004-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00005-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00006-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00007-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00008-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00009-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00010-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00011-0f17b9e5-4d14-4bf2-8be8-a5fe0da0dc2f-c000.txt', '-output', 'hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result', '-mapper', 'lexicraft/MapReduce/WordCount/mapper.py', '-reducer', 'lexicraft/MapReduce/WordCount/reducer.py', '-file', 'lexicraft/MapReduce/WordCount/mapper.py', '-file', 'lexicraft/MapReduce/WordCount/reducer.py']
Running Hadoop MapReduce for word count...
Hadoop Streaming Command Output:
packageJobJar: [lexicraft/MapReduce/WordCount/mapper.py, lexicraft/MapReduce/WordCount/reducer.py, /tmp/hadoop-unjar4024617370228894592/] [] /tmp/streamjob6278587970342902962.jar tmpDir=null

[Stage 0:>                                                        (0 + 12) / 12][Stage 0:======================================>                   (8 + 4) / 12][Stage 0:===============================================>         (10 + 2) / 12]                                                                                Raw Data has been successfully appended to HDFS:  DE-prj/RawData
[Stage 0:>                                                        (0 + 12) / 12]                                                                                Sentence data has been successfully appended to HDFS:  DE-prj/Sentences
[Stage 0:>                                                        (0 + 12) / 12]                                                                                Word data has been successfully appended to HDFS:  DE-prj/Words
Performing Lexicon Creation...
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/torch_model/rnn.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(pth, map_location='cpu'))
You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers
Traceback (most recent call last):
  File "/home/student/DE_malay_news/run-lexicraft.py", line 70, in start_lexicraft
    lexiconBuilder.build_lexicon()
  File "/home/student/DE_malay_news/lexicraft/lexicon_creation.py", line 175, in build_lexicon
    wordRows_rdd = df.rdd.repartition(3)
AttributeError: 'NoneType' object has no attribute 'rdd'
Exception has occured. Retrying the process in 45 seconds -  0
Performing Data Collection from time 2024-12-21 06:05:50.395568...
Links crawl to datetime  2024-12-21 16:14:35.053899
Links Crawling Starts...
Article teaser found on page 0.
Current no. of link: 20
Article teaser found on page 1.
Current no. of link: 36
Current is in demo stage, 1 number of article(s) will be scrapped
[Stage 1:>                                                          (0 + 3) / 3]/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
[Stage 1:=======================================>                   (2 + 1) / 3]                                                                                Data sent to topic beritaH
Number of articles data sent 1
Performing Data Transformation...
Collecting Data From Kafka...
After dropped duplicated articles which exist in database(DE-prj/RawData),
Number of articles left to be processed: 1
[Stage 11:===================================================>    (11 + 1) / 12]                                                                                Breaking raw data into list of sentences...
[Stage 21:==========================================>              (9 + 3) / 12]                                                                                Breaking sentences into words...
[Stage 22:==========================================>              (9 + 3) / 12]                                                                                [Stage 23:==========================================>              (9 + 3) / 12]                                                                                Traceback (most recent call last):
  File "/home/student/DE_malay_news/run-lexicraft.py", line 52, in start_lexicraft
    result = Transformation.wordCountMapReduce()
  File "/home/student/DE_malay_news/lexicraft/transformation.py", line 220, in wordCountMapReduce
    inputFiles = cls.get_processed_words_file_path("/user/student/DE-prj/TempWords/")
  File "/home/student/DE_malay_news/lexicraft/transformation.py", line 283, in get_processed_words_file_path
    file_status = fs.listStatus(path)
  File "/home/student/de-prj/de-venv/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/student/de-prj/de-venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 179, in deco
    return f(*a, **kw)
  File "/home/student/de-prj/de-venv/lib/python3.10/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o563.listStatus.
: java.io.FileNotFoundException: File hdfs://localhost:9000/user/student/DE-prj/TempWords does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:1104)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:147)
	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1175)
	at org.apache.hadoop.hdfs.DistributedFileSystem$24.doCall(DistributedFileSystem.java:1172)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:1182)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)

Exception has occured. Retrying the process in 45 seconds -  1
Performing Data Collection from time 2024-12-21 06:05:50.395568...
Links crawl to datetime  2024-12-21 16:15:56.510178
Links Crawling Starts...
Article teaser found on page 0.
Current no. of link: 20
Article teaser found on page 1.
Current no. of link: 36
Current is in demo stage, 1 number of article(s) will be scrapped
[Stage 1:>                                                          (0 + 3) / 3]/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
[Stage 1:===================>                                       (1 + 2) / 3][Stage 1:=======================================>                   (2 + 1) / 3]                                                                                Data sent to topic beritaH
Number of articles data sent 1
Performing Data Transformation...
Collecting Data From Kafka...
After dropped duplicated articles which exist in database(DE-prj/RawData),
Number of articles left to be processed: 1
[Stage 18:==============================================>         (10 + 2) / 12]                                                                                Breaking raw data into list of sentences...
[Stage 21:==========================================>              (9 + 3) / 12]                                                                                Breaking sentences into words...
[Stage 22:==============================================>         (10 + 2) / 12]                                                                                [Stage 23:==========================================>              (9 + 3) / 12]                                                                                /bin/sh: 1: hdfs: not found
['/home/hduser/hadoop3/bin/hadoop', 'jar', '/home/hduser/hadoop3/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar', '-input', 'hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00000-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00001-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00002-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00003-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00004-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00005-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00006-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00007-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00008-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00009-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00010-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00011-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt', '-output', 'hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result', '-mapper', 'lexicraft/MapReduce/WordCount/mapper.py', '-reducer', 'lexicraft/MapReduce/WordCount/reducer.py', '-file', 'lexicraft/MapReduce/WordCount/mapper.py', '-file', 'lexicraft/MapReduce/WordCount/reducer.py']
Running Hadoop MapReduce for word count...
Error running the Hadoop streaming job:
2024-12-21 16:16:32,552 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
2024-12-21 16:16:33,128 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:16:33,386 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:16:33,471 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result already exists
Streaming Command Failed!

Fail to run Hadoop Map Reduce
Retrying...
Performing Data Collection from time 2024-12-21 06:05:50.395568...
Links crawl to datetime  2024-12-21 16:16:34.270231
Links Crawling Starts...
Article teaser found on page 0.
Current no. of link: 20
Article teaser found on page 1.
Current no. of link: 36
Current is in demo stage, 1 number of article(s) will be scrapped
[Stage 0:>                                                        (0 + 12) / 12][Stage 1:>                                                          (0 + 3) / 3]/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
[Stage 1:===================>                                       (1 + 2) / 3][Stage 1:=======================================>                   (2 + 1) / 3]                                                                                Data sent to topic beritaH
Number of articles data sent 1
Performing Data Transformation...
Collecting Data From Kafka...
After dropped duplicated articles which exist in database(DE-prj/RawData),
Number of articles left to be processed: 1
[Stage 11:===================================================>    (11 + 1) / 12]                                                                                [Stage 18:===================================================>    (11 + 1) / 12]                                                                                Breaking raw data into list of sentences...
[Stage 21:===================================================>    (11 + 1) / 12]                                                                                Breaking sentences into words...
[Stage 22:===================================================>    (11 + 1) / 12]                                                                                [Stage 23:===================================================>    (11 + 1) / 12]                                                                                /bin/sh: 1: hdfs: not found
['/home/hduser/hadoop3/bin/hadoop', 'jar', '/home/hduser/hadoop3/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar', '-input', 'hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00000-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00001-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00002-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00003-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00004-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00005-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00006-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00007-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00008-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00009-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00010-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00011-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt', '-output', 'hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result', '-mapper', 'lexicraft/MapReduce/WordCount/mapper.py', '-reducer', 'lexicraft/MapReduce/WordCount/reducer.py', '-file', 'lexicraft/MapReduce/WordCount/mapper.py', '-file', 'lexicraft/MapReduce/WordCount/reducer.py']
Running Hadoop MapReduce for word count...
Error running the Hadoop streaming job:
2024-12-21 16:17:08,333 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
2024-12-21 16:17:08,979 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:17:09,151 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:17:09,243 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result already exists
Streaming Command Failed!

Fail to run Hadoop Map Reduce
Retrying...
Performing Data Collection from time 2024-12-21 06:05:50.395568...
Links crawl to datetime  2024-12-21 16:17:10.117030
Links Crawling Starts...
Article teaser found on page 0.
Current no. of link: 20
Article teaser found on page 1.
Current no. of link: 36
Current is in demo stage, 1 number of article(s) will be scrapped
[Stage 0:>                                                        (0 + 12) / 12][Stage 1:>                                                          (0 + 3) / 3]/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3397
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
/home/student/de-prj/de-venv/lib/python3.10/site-packages/malaya/tokenizer.py:214: FutureWarning: Possible nested set at position 3927
  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))
[Stage 1:=======================================>                   (2 + 1) / 3]                                                                                Data sent to topic beritaH
Number of articles data sent 1
Performing Data Transformation...
Collecting Data From Kafka...
After dropped duplicated articles which exist in database(DE-prj/RawData),
Number of articles left to be processed: 1
[Stage 11:==========================================>              (9 + 3) / 12]                                                                                Breaking raw data into list of sentences...
[Stage 21:==========================================>              (9 + 3) / 12][Stage 21:===================================================>    (11 + 1) / 12]                                                                                Breaking sentences into words...
[Stage 22:==========================================>              (9 + 3) / 12][Stage 22:===================================================>    (11 + 1) / 12]                                                                                [Stage 23:==========================================>              (9 + 3) / 12][Stage 23:===================================================>    (11 + 1) / 12]                                                                                /bin/sh: 1: hdfs: not found
['/home/hduser/hadoop3/bin/hadoop', 'jar', '/home/hduser/hadoop3/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar', '-input', 'hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00000-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00001-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00002-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00003-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00004-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00005-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00006-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00007-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00008-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00009-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00010-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt,hdfs://localhost:9000/user/student/DE-prj/TempWords/part-00011-a79830b9-3334-4305-b1b0-462de0aedbb5-c000.txt', '-output', 'hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result', '-mapper', 'lexicraft/MapReduce/WordCount/mapper.py', '-reducer', 'lexicraft/MapReduce/WordCount/reducer.py', '-file', 'lexicraft/MapReduce/WordCount/mapper.py', '-file', 'lexicraft/MapReduce/WordCount/reducer.py']
Running Hadoop MapReduce for word count...
Error running the Hadoop streaming job:
2024-12-21 16:17:42,719 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
2024-12-21 16:17:43,338 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:17:43,466 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /127.0.0.1:8032
2024-12-21 16:17:43,546 ERROR streaming.StreamJob: Error Launching job : Output directory hdfs://localhost:9000/user/student/DE-prj/MR_WC_Result already exists
Streaming Command Failed!

Fail to run Hadoop Map Reduce
Retrying...
Errors occur even after 5 times of retry
