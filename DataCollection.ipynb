{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f862eafb-e109-4ac2-aba8-6b3f549d76ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yang': {'meanings': ['(Lin) kata penghubung utk menyatakan bahawa kata keterangan berikutnya dipentingkan atau menunjukkan kelainan', '(Lin) kata penghubung utk menyatakan bahawa katakata (ayat) berikutnya ialah penjelasan utk kata-kata sebelumnya', 'kata yg digunakan sbg kata penyerta, kata yg menentukan kata benda, kata sandang', 'sl adapun akan', 'bp kata peng-hubung utk menyatakan isi atau huraiankata (ayat) sebelumnya, bahawa', '= yang-yang dewa'], 'synonym': []}}\n",
      "Cleaned Result: {'yang': {'meanings': ['(lin) kata penghubung untuk menyatakan bahawa kata keterangan berikutnya dipentingkan atau menunjukkan kelainan', '(lin) kata penghubung untuk menyatakan bahawa katakan (ayat) berikutnya ialah penjelasan untuk kata-kata sebelumnya', 'kata yang digunakan sebagai kata penyerta, kata yang menentukan kata benda, kata sandang', 'sama adapun akan', 'bapa kata penpergi-hubung untuk menyatakan isi atau huraiankata (ayat) sebelumnya, bahawa', '= yang-yang dewa'], 'synonym': []}}\n"
     ]
    }
   ],
   "source": [
    "## Data scrapping prpm\n",
    "from PyClasses.Scrapers.PRPMScraper import PRPMScraper\n",
    "from PyClasses.Scrapers.PERIScraper import PeriScraper\n",
    "from PyClasses.Scrapers.PRPMCleaner import PRPMCleaner\n",
    "\n",
    "PRPMscrap = PRPMScraper()\n",
    "prpm_cleaner = PRPMCleaner()\n",
    "\n",
    "word = 'yang'\n",
    "result = PRPMscrap.findWordMetaData(word)\n",
    "print(result)\n",
    "\n",
    "if result and 'meanings' in result[word]:\n",
    "    raw_meanings = result[word]['meanings']\n",
    "    cleaned_meanings = prpm_cleaner.clean_all_meanings(raw_meanings)\n",
    "    result[word]['meanings'] = cleaned_meanings\n",
    "\n",
    "# Output cleaned result\n",
    "print(\"Cleaned Result:\", result)\n",
    "\n",
    "#found smth can be preprocess if not done here, like there will have '\\xa' character in the result string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b531d18a-aca2-4941-8779-c998b0655c89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article teaser found on page 0.\n",
      "Current no. of link: 20\n",
      "Article teaser found on page 1.\n",
      "Current no. of link: 39\n",
      "Article teaser found on page 2.\n",
      "Current no. of link: 58\n",
      "Article teaser found on page 3.\n",
      "Current no. of link: 77\n",
      "Article teaser found on page 4.\n",
      "Current no. of link: 96\n",
      "Article teaser found on page 5.\n",
      "Current no. of link: 115\n",
      "Article teaser found on page 6.\n",
      "Current no. of link: 134\n",
      "Article teaser found on page 7.\n",
      "Current no. of link: 153\n",
      "Article teaser found on page 8.\n",
      "Current no. of link: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===>                                                     (1 + 17) / 18]Timeout error on '/berita/nasional/2024/12/1335219/purata-gaji-upah-bulanan-pekerja-mahir-kini-meningkat-75-peratus'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1335482/inisiatif-kelas-hibrid-terima-maklum-balas-positif-kpm-cadang'. Scrap Attempt: 1 time(s)\n",
      "[Stage 0:============>                                            (4 + 14) / 18]Timeout error on '/berita/nasional/2024/12/1335414/tunggakan-caj-rawatan-pekerja-asing-kkm-teliti-prosedur-prosedur'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1335125/nestl%C3%A9-malaysia-teruja-perkukuh-kerjasama-dengan-media-prima'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1335060/anwar-mahu-pembinaan-rumah-mampu-milik-pentingkan-keselesaan-semua'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1335700/kkm-mula-siasat-dakwaan-hospital-swasta-tahan-jenazah-bayi-dua'. Scrap Attempt: 1 time(s)\n",
      "[Stage 0:===============>                                         (5 + 13) / 18]Timeout error on '/berita/nasional/2024/12/1335480/kerajaan-berjaya-dapat-perintah-halang-psi-guna-as340-juta'. Scrap Attempt: 1 time(s)\n",
      "[Stage 0:===============================================>         (15 + 3) / 18]Timeout error on '/berita/nasional/2024/12/1335246/istana-pahang-nafi-tengku-mahkota-pahang-bakal-berkahwin-april-depan'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1334886/70-pelajar-termasuk-bukan-islam-terima-biasiswa-yayasan-waqaf'. Scrap Attempt: 1 time(s)\n",
      "Timeout error on '/berita/nasional/2024/12/1335096/takrifan-pengelasan-t15-dijangka-umum-suku-pertama-tahun-depan'. Scrap Attempt: 1 time(s)\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Start Time: 2024-12-11 23:42:08.340808\n",
      "Processing End Time: 2024-12-11 23:52:49.192608\n",
      "Total Time Taken: 0:10:40.851800\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from PyClasses.Scrapers.BHarianScraper import BHarianScraper\n",
    "from pyspark.sql import SparkSession\n",
    "from selenium import webdriver\n",
    "\n",
    "def ArticleDataCollection(fromDate,categoryLink):\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"DE_malay_news\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    ## crawl links\n",
    "    bharianScraper = BHarianScraper()\n",
    "    timeNow = datetime.now()\n",
    "    crawlledUrls = bharianScraper.scrapArticleLinks(fromDate,categoryLink)\n",
    "    url_RDD = spark.sparkContext.parallelize(crawlledUrls)\n",
    "    if crawlledUrls is None:\n",
    "        print('failed to get article links')\n",
    "        return 'fail'\n",
    "    \n",
    "    ## parallelize process to scrap data\n",
    "    scrappedData = url_RDD.map(BHarianScraper.scrapOneArticle).collect()\n",
    "    for data in scrappedData:\n",
    "        if data is None:\n",
    "            scrappedData.remove(data)\n",
    "            \n",
    "    ## Save Data into HDFS\n",
    "    df = spark.createDataFrame(scrappedData)\n",
    "    df.write.format(\"parquet\").mode(\"overwrite\").save(\"DE-prj/RawData\")\n",
    "    timeEnd = datetime.now() \n",
    "    timeTaken = timeEnd - timeNow\n",
    "    print(f'Processing Start Time: {timeNow}')\n",
    "    print(f'Processing End Time: {timeEnd}')\n",
    "    print(f'Total Time Taken: {timeTaken}')\n",
    "    \n",
    "    print('done')\n",
    "    return 'success'\n",
    "\n",
    "ArticleDataCollection(datetime(2024,12,10),'/berita/nasional')\n",
    "<<<<<<< HEAD:Webscraping.ipynb
   "execution_count": null,
   "id": "fe3eb838-a9ab-4b5d-9ebe-c53b9ba53494",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313747a-9d3d-47f6-8569-d0e7f53a539f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387dc44-7f18-4230-ab1b-ccccd2518932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for link in bharianScraper.relLinkToArticle_all:\n",
    "#     print(link)\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ReadRawData\")\\\n",
    "        .getOrCreate()\n",
    "df_read = spark.read.parquet(\"DE-prj/RawData\")\n",
    "df_read.show()\n",
    "\n",
    "\n",
    "df_filter = df_read.where(df_read['title'] == '')\n",
    "df_filter.show()\n",
    "\n",
    "print(df_read.count())\n",
    "\n",
    "\n",
    "# Get the first 5 rows\n",
    "rows = df_read.take(125)\n",
    "\n",
    "# Print each row\n",
    "print(rows[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8924d77-4ee4-4b3b-a93d-20b544577b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data in rows:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e525e09-006d-4809-b451-d69fb1c5a84e",
   "metadata": {},
   "source": [
    "# PERIBAHASA STARTS HERE YA !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b39cd3-b1e1-4142-b8fa-87622637ad86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peri_scrap = PeriScraper()\n",
    "\n",
    "proverbs_data_AM = peri_scrap.scrape_page(peri_scrap.AM_Url)\n",
    "print(\"Proverbs from A–M:\")\n",
    "\n",
    "for proverb, meaning in proverbs_data_AM:\n",
    "    print(f\"Peribahasa: {proverb} || Maksud: {meaning}\")\n",
    "\n",
    "proverbs_data_NZ = peri_scrap.scrape_page(peri_scrap.NZ_Url)\n",
    "print(\"\\nProverbs from N–Z:\")\n",
    "\n",
    "for proverb, meaning in proverbs_data_NZ:\n",
    "    print(f\"Peribahasa: {proverb} || Maksud: {meaning}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
