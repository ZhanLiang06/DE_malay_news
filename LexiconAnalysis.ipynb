{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f3c7e3-cf12-419f-832f-8c85420cee80",
   "metadata": {},
   "source": [
    "# Lexicon Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8b2048-3a86-47eb-b8b5-3090f294551e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lexicraft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlexicraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Analysis\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo4j+s://231511d9.databases.neo4j.io\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lexicraft'"
     ]
    }
   ],
   "source": [
    "from lexicraft import Analysis\n",
    "from pyspark.sql import SparkSession\n",
    "uri = \"neo4j+s://231511d9.databases.neo4j.io\"\n",
    "auth = (\"neo4j\", \"m6fWF6qQUe6yGcZ81yAX0XG425OncyOB28A30vI9VvM\") ## using liangzlau personal account\n",
    "spark = SparkSession.builder.appName(\"DE-prj\").getOrCreate()\n",
    "analysis_instance = Analysis(spark,uri,auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8650d9f3-b0c9-4219-a182-a4e708042dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established Connection\n",
      "Successfully retrieved all words no. of words = 3749!\n",
      "Message sent to word_length_analysis partition 0 at offset 10\n",
      "Established Connection\n",
      "Successfully run \n",
      "            MATCH (n:WORD)-[:LEMMATIZED]->(lematizedNode)\n",
      "            RETURN DISTINCT lematizedNode.word AS lemmatized\n",
      "        !\n",
      "Message sent to lemma_length_analysis partition 0 at offset 4\n",
      "Established Connection\n",
      "Successfully run \n",
      "        MATCH (n:WORD)\n",
      "        WITH COUNT(n) AS totalWords\n",
      "        MATCH (n:PERIBAHASA)\n",
      "        RETURN totalWords, COUNT(n) AS totalPeri;\n",
      "        !\n",
      "Message sent to lexicon_analysis partition 0 at offset 4\n",
      "Established Connection\n",
      "Successfully run \n",
      "            MATCH (n:WORD)\n",
      "            RETURN n.POS AS pos, COUNT(n) AS total_count\n",
      "            ORDER BY total_count DESC\n",
      "            !\n",
      "Message sent to POSDistribution partition 0 at offset 3\n",
      "Established Connection\n",
      "Successfully run \n",
      "            MATCH (n:WORD)\n",
      "            RETURN n.Label AS label, COUNT(n) AS total_count\n",
      "            ORDER BY total_count DESC\n",
      "            !\n",
      "Message sent to sentiment_dist_analysis partition 0 at offset 3\n",
      "Established Connection\n",
      "Successfully run \n",
      "            MATCH (n:WORD)\n",
      "            RETURN n.word AS word, n.word_count AS count\n",
      "            ORDER BY n.word_count DESC\n",
      "            LIMIT 15\n",
      "            !\n",
      "Message sent to word_freq_with_stopwords partition 0 at offset 2\n",
      "Established Connection\n",
      "Successfully run \n",
      "            MATCH (n:WORD)\n",
      "            RETURN n.word AS word, n.word_count AS count\n",
      "            ORDER BY n.word_count DESC\n",
      "            LIMIT 1500\n",
      "            !\n",
      "Message sent to word_freq_without_stopwords partition 0 at offset 2\n"
     ]
    }
   ],
   "source": [
    "analysis_instance.word_length_analysis()\n",
    "analysis_instance.lemma_length_analysis()\n",
    "analysis_instance.lexicon_analysis()\n",
    "analysis_instance.morphological_analysis() \n",
    "analysis_instance.POSDistribution()\n",
    "analysis_instance.sentiment_dist()\n",
    "analysis_instance.word_freq_with_stopwords()\n",
    "analysis_instance.word_freq_without_stopwords()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
